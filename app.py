import streamlit as st
from spark_chat_ai import SparkChatAI
import requests
import json
import os
import uuid

# Streamlit é¡µé¢é…ç½®
st.set_page_config(page_title="æ˜ æœˆ", page_icon="ğŸŒ™", layout="wide")
st.title("æ˜ æœˆ ğŸŒ™")
st.write("æœˆå‡ºçšå…®ï¼Œä½¼äººåƒšå…®ã€‚èˆ’çªˆçº å…®ï¼ŒåŠ³å¿ƒæ‚„å…®ã€‚")

# API å‡­æ®è¾“å…¥æ¡†
st.sidebar.title("è®¾ç½®APIå‡­æ®")
app_id = st.sidebar.text_input("SPARKAI_APP_ID")
api_secret = st.sidebar.text_input("SPARKAI_API_SECRET", type="password")
api_key = st.sidebar.text_input("SPARKAI_API_KEY", type="password")
fish_api_key = st.sidebar.text_input("Fish Audio API Key", type="password")

# å®šä¹‰æ¨¡å‹é€‰é¡¹å’Œå¯¹åº”çš„ ID
model_options = {
    "é›·å†›": "738d0cc1a3e9430a9de2b544a466a7fc",
    "å­¦å§": "7f92f8afb8ec43bf81429cc1c9199cb1",
    "å¤®è§†é…éŸ³": "59cb5986671546eaa6ca8ae6f29f6d22",
    "è”¡å¾å¤": "e4642e5edccd4d9ab61a69e82d4f8a14",
    "ä¸çœŸ": "54a5170264694bfc8e9ad98df7bd89c3"
}

# æ–‡æœ¬åˆ°è¯­éŸ³è½¬æ¢å‡½æ•°
def text_to_speech(text, reference_id, model_name, fish_api_key):
    url = "https://api.fish.audio/v1/tts"
    headers = {
        "Authorization": f"Bearer {fish_api_key}",
        "Content-Type": "application/json"
    }

    payload = {
        "text": text,
        "reference_id": reference_id,
        "chunk_length": 200,
        "normalize": True,
        "format": "mp3",
        "mp3_bitrate": 64,
        "latency": "normal"
    }

    # å‘é€ POST è¯·æ±‚åˆ° Fish Audio API
    response = requests.post(url, json=payload, headers=headers)

    if response.status_code == 200:
        # åˆ›å»ºæ¨¡å‹å¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶å¤¹
        audio_folder = f"audios/{model_name}"
        os.makedirs(audio_folder, exist_ok=True)
        # ç”Ÿæˆå”¯ä¸€çš„éŸ³é¢‘æ–‡ä»¶åï¼Œä½¿ç”¨ UUID
        unique_id = uuid.uuid4().hex
        audio_filename = f"{unique_id}.mp3"
        audio_path = os.path.join(audio_folder, audio_filename)
        # ä¿å­˜ç”Ÿæˆçš„è¯­éŸ³æ–‡ä»¶
        with open(audio_path, "wb") as output_file:
            output_file.write(response.content)
        return audio_path
    else:
        st.error(f"ç”Ÿæˆè¯­éŸ³æ—¶å‡ºé”™: {response.status_code}, {response.content}")
        return None

# æ£€æŸ¥æ˜¯å¦å¡«å…¥äº† API å‡­æ®
if all([app_id, api_secret, api_key, fish_api_key]):
    # ç”¨æˆ·é€šè¿‡ä¸‹æ‹‰é€‰é¡¹é€‰æ‹©æ¨¡å‹
    model_name = st.sidebar.selectbox("è¯·é€‰æ‹©ä¸€ä¸ªèŠå¤©å¯¹è±¡", options=list(model_options.keys()))
    selected_model_id = model_options[model_name]
    st.sidebar.write(f"å·²é€‰æ‹©: {model_name}")

    # ä½¿ç”¨ st.session_state æ¥ä¿æŒæ¯ä¸ªæ¨¡å‹çš„ chat_ai å®ä¾‹
    if 'chat_ai_dict' not in st.session_state:
        st.session_state.chat_ai_dict = {}
    if 'chat_history_dict' not in st.session_state:
        st.session_state.chat_history_dict = {}
    chat_ai_dict = st.session_state.chat_ai_dict
    chat_history_dict = st.session_state.chat_history_dict

    # åˆå§‹åŒ–æ˜Ÿç«å¤§æ¨¡å‹
    if model_name not in chat_ai_dict:
        chat_ai_dict[model_name] = SparkChatAI(app_id, api_secret, api_key, model_name)
    chat_ai = chat_ai_dict[model_name]

    # åˆå§‹åŒ–èŠå¤©å†å²
    if model_name not in chat_history_dict:
        chat_history_dict[model_name] = []
    chat_history = chat_history_dict[model_name]

    # æ–°å¢ï¼šé‡ç½®å¯¹è¯æŒ‰é’®
    if st.sidebar.button("é‡ç½®å¯¹è¯"):
        chat_ai.reset_memory()
        chat_history.clear()
        # åˆ é™¤æ¨¡å‹å¯¹åº”çš„èŠå¤©è®°å½•æ–‡ä»¶
        history_file = f"history_{model_name}.json"
        if os.path.exists(history_file):
            os.remove(history_file)
        # åˆ é™¤æ¨¡å‹å¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶å¤¹
        audio_folder = f"audios/{model_name}"
        if os.path.exists(audio_folder):
            for file in os.listdir(audio_folder):
                os.remove(os.path.join(audio_folder, file))
            os.rmdir(audio_folder)
        st.sidebar.success(f"{model_name} çš„å¯¹è¯å·²é‡ç½®ï¼")

    # åŠ è½½å†å²èŠå¤©è®°å½•
    history_file = f"history_{model_name}.json"
    if os.path.exists(history_file) and not chat_history:
        with open(history_file, "r", encoding="utf-8") as f:
            chat_history.extend(json.load(f))

    # å®šä¹‰å¤´åƒè·¯å¾„
    user_avatar_path = "avatars/user.png"  # ç”¨æˆ·å¤´åƒ
    assistant_avatar_path = f"avatars/{model_name}.png"  # æ¨¡å‹å¯¹åº”çš„å¤´åƒ

    # æ˜¾ç¤ºèŠå¤©å†å²
    st.write(f"ä¸ {model_name} çš„èŠå¤©è®°å½•ï¼š")
    for msg in chat_history:
        role = msg["role"]
        content = msg["content"]
        if role == "user":
            with st.chat_message("user", avatar=user_avatar_path):
                st.write(content)
        else:
            with st.chat_message("assistant", avatar=assistant_avatar_path):
                st.write(content)
                # æ˜¾ç¤ºå¯¹åº”çš„éŸ³é¢‘
                audio_path = msg.get("audio_path")
                if audio_path and os.path.exists(audio_path):
                    st.audio(audio_path, format='audio/mp3')

    # å›ºå®šè¾“å…¥æ¡†åœ¨é¡µé¢åº•éƒ¨
    prompt = st.chat_input("åœ¨è¿™é‡Œè¾“å…¥æ¶ˆæ¯...")  # ç§»é™¤ avatar å‚æ•°

    if prompt:
        # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°èŠå¤©å†å²å¹¶ä¿å­˜
        message = {"role": "user", "content": prompt}
        chat_history.append(message)
        with open(history_file, "w", encoding="utf-8") as f:
            json.dump(chat_history, f, ensure_ascii=False, indent=4)

        # åœ¨ç•Œé¢ä¸Šæ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user", avatar=user_avatar_path):
            st.write(prompt)

        # è°ƒç”¨æ˜Ÿç«å¤§æ¨¡å‹è·å–å›å¤
        with st.chat_message("assistant", avatar=assistant_avatar_path):
            # æ·»åŠ åŠ è½½åŠ¨ç”»
            with st.spinner("æ­£åœ¨ç”Ÿæˆå›å¤ï¼Œè¯·ç¨å€™..."):
                response = chat_ai.get_response(prompt)
                # æ›´æ–°åŠ©æ‰‹æ¶ˆæ¯
                st.write(response)

            # ä½¿ç”¨æ˜Ÿç«å¤§æ¨¡å‹çš„å›ç­”è°ƒç”¨ Fish Audio è¿›è¡Œæ–‡æœ¬åˆ°è¯­éŸ³è½¬æ¢
            with st.spinner("æ­£åœ¨ç”Ÿæˆè¯­éŸ³ï¼Œè¯·ç¨å€™..."):
                audio_path = text_to_speech(response, selected_model_id, model_name, fish_api_key)
                if audio_path:
                    # æ’­æ”¾ç”Ÿæˆçš„è¯­éŸ³
                    st.audio(audio_path, format='audio/mp3')
                else:
                    st.error("è¯­éŸ³ç”Ÿæˆå¤±è´¥")

        # æ·»åŠ æ¨¡å‹å›å¤åˆ°èŠå¤©å†å²å¹¶ä¿å­˜ï¼ŒåŒ…æ‹¬éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        message = {"role": "assistant", "content": response, "audio_path": audio_path}
        chat_history.append(message)
        with open(history_file, "w", encoding="utf-8") as f:
            json.dump(chat_history, f, ensure_ascii=False, indent=4)

else:
    st.warning("è¯·åœ¨ä¾§è¾¹æ å¡«å†™å®Œæ•´çš„ API å‡­æ®ï¼")